{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# @zhangjoy\n",
    "# @构建主题因子\n",
    "# @20180327\n",
    "import os\n",
    "import csv\n",
    "import tushare as ts\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jieba\n",
    "import sys\n",
    "import time\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer # 词频统计\n",
    "from sklearn.decomposition import LatentDirichletAllocation # LDA\n",
    "from sklearn.cluster import KMeans # k均值聚类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "comment = []\n",
    "path = \"/Users/zhangjoy/Documents/vscode/py_project/lda/data/cjpl/\"   # 评论内容的存储路径\n",
    "filenames = os.listdir(path)\n",
    "filenames.sort() # 列表排序\n",
    "for filename in filenames:\n",
    "    filepath = path + filename\n",
    "    # print(filepath)\n",
    "    with open(filepath, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        comment_text = [row[7] for row in reader]\n",
    "        comment.append(comment_text)\n",
    "print(len(comment)) # 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Getting data:]###############################"
     ]
    }
   ],
   "source": [
    "# 得到所有股票的代码和中文名字\n",
    "stock_name = ts.get_stock_basics()['name'] # 股票名称\n",
    "stock_code = stock_name.index.tolist() # 股票代码\n",
    "# 获得所有的概念列表、行业列表、地域列表、公司名称等\n",
    "concept = ts.get_concept_classified()['c_name'].drop_duplicates().values.tolist() # 概念列表 163\n",
    "industry = ts.get_industry_classified('sw')['c_name'].drop_duplicates().values.tolist() # 申万行业列表 129 > 110\n",
    "place = ts.get_area_classified()['area'].drop_duplicates().values.tolist() # 获取地域列表 32 省份\n",
    "\n",
    "broker = ts.broker_tops()[\"broker\"] # 获取营业部信息：1062\n",
    "pattern = re.compile(u'.*有限.*?公司') # 最小匹配[*?]到'有限 公司'\n",
    "company = [\" \".join(pattern.findall(s)) for s in broker] # list\n",
    "company = pd.Series(company).drop_duplicates().values.tolist() # 证券公司：94"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 将上述信息作为新词录入词典\n",
    "for d in stock_name:\n",
    "    jieba.add_word(d)\n",
    "for d in stock_code:\n",
    "    jieba.add_word(d)\n",
    "for d in concept:\n",
    "    jieba.add_word(d)\n",
    "for d in industry:\n",
    "    jieba.add_word(d)\n",
    "# for d in place:\n",
    "#     jieba.add_word(d)    \n",
    "for d in company:\n",
    "    jieba.add_word(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 启用自定义词典\n",
    "jieba.load_userdict(\"/Users/zhangjoy/Documents/vscode/py_project/lda/data/userdict.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 停用词列表\n",
    "stop =[line.strip() for line in open('/Users/zhangjoy/Documents/vscode/py_project/lda/data/stopwords.txt').readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pattern = re.compile(u'[\\u4e00-\\u9fa5]{2,20}') # 中文"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comment_0 preprocessing time using 42.37331 s\n",
      "comment_1 preprocessing time using 86.78557 s\n",
      "comment_2 preprocessing time using 91.81986 s\n",
      "comment_3 preprocessing time using 138.17313 s\n",
      "comment_4 preprocessing time using 156.55418 s\n",
      "comment_5 preprocessing time using 137.22266 s\n",
      "comment_6 preprocessing time using 120.33943 s\n",
      "comment_7 preprocessing time using 113.42303 s\n",
      "comment_8 preprocessing time using 96.95149 s\n",
      "comment_9 preprocessing time using 81.75059 s\n",
      "comment_10 preprocessing time using 84.84410 s\n",
      "comment_11 preprocessing time using 106.20842 s\n",
      "comment_12 preprocessing time using 100.54806 s\n",
      "comment_13 preprocessing time using 112.86744 s\n",
      "comment_14 preprocessing time using 105.31068 s\n",
      "comment_15 preprocessing time using 140.74239 s\n",
      "comment_16 preprocessing time using 192.13992 s\n",
      "comment_17 preprocessing time using 342.51002 s\n",
      "股市 收盘 红四月 爽约 大盘 震荡 上行 判若两人 一路 阴跌 上证综指 创业板指 均 小幅 下跌 收场 债市 风险 暴露 一时间 风声鹤唳 机构 惊慌失色 前 股市 债市 表现 动荡 公募基金 表现 分化 很大 但前 里 基金 取得 不错 正收 基金君 一起 主动 股票型基金 平均 跌 次新基金 逆势 获 正收益 前 主动 股票型基金 单位 净值 平均 下跌 基金 分化 十分 明显 成立 圆信 永丰 优 加生 嘉实 环保 低碳 工银 文体 产业 和泓德 战略转型 次新基金 稳健 建仓 节奏 前 取得 正回报 基金 告亏 特别 基金 亏损 减亏 压力 甚大 混合型基金 跌幅 超 两成 最多 跌 混合型基金 数量 最多 基金 类别 各类 混合型基金 总数 混合基金 分化 同样 十分 明显 表现 最好 混合基金 前 收益率 均 动荡市场 着实 前海 开源 金银珠宝 赚 居首 主要 受益 金价 大涨 刺激 相关 个股 不俗 表 数量 混合基金 取得 正收益 跌幅 较大 混合基金 占 高 只前 跌幅 特别 混合基金 跌幅 远超 打新基金 部分 基金 赎回费 赚 前 相当 数量 绝对收益 策略 基金 打新基金 为主 遭遇 比例 净 赎回 依靠 赎回费 计入 资产 净值 飙升 成为 今年以来 赚钱 基金 群体 家 基金 跌 一塌糊涂 基金 口吃 肉 原来 股票 赚 赎回费 潜伏 机构 占 比高 打新基金 成为 投资 热 捧 盈利模式 基金君 注意 主流 财经 媒体 基金 当做 绩优 基金 报道 分析 季报 持仓 重仓股 观点 基金君 只能 保本基金 好发 不好 做 多只 基金 亏超 保本基金 毫无疑问 股灾 基金 产品 中 爆 投资者 本金 保护 强烈 需求 类产品 热卖 大半年 股市 债市 双 重大 震荡 保本基金 陷入 好发 不好 做 困境 前 保本基金 平均 小幅 亏损 基金 实现 正收益 收益 最高 新华 阿里 一号 赚 取得 正收益 保本基金 净值 涨幅 均 保本基金 前 亏损 跌幅 跌幅 最大 大跌眼镜 纯债基金 遭遇 黑色 平均 收益 由正 转负 纯债基金 表现 债市 遭遇 黑色 纯债基金 今年以来 收益 大幅 下滑 统计 显示 余只 纯债基金 前 平均 收益 跌为 零 有近 取得 正收益 收益 十分 有限 收益率 表现 最好 债基 收益 均 百只 纯债基金 收益 告负 特别 跌幅 表现 最差 跌幅 均 原来 纯债基金 跌 任性 二级债基 股债 双杀 前 亏大 前 遭遇 股债 双杀 二级债基 前 总体 表现 惨淡 统计 显示 二级债基 前 平均 亏损 仅 基金 取得 正收益 告负 表现 最好 工 银瑞信 双利 债券 单位 净值 上涨 唯一 收益 超 二级债基 二级债基 亏损 亏损 幅度 表现 最差 基金 亏损 均 货币基金 收益 不断 下滑 基金 收益 超 当前 基金业 规模 最大 基金 类别 货币 基金 今年以来 收益 走低 相比 股债 悲惨 表现 货币基金 获得 资金 流入 意外 统计 显示 余只 货币基金 收益率 仅 收益率 最高 中欧 滚钱宝 收益率 多数 货币基金 七日年化 回报 低 活期 利息 优势 基金 大宗商品基金 强劲 反弹 港股 基金 依然 惨淡 前 海外 同样 出现 较大 动荡 大宗商品 强劲 超跌 反弹 成为 重要 正收益 大宗商品基金 成为 表现 最好 基金 类别 收益 超 基金 大宗商品 主题 基金 占据 中银 全球 资源 单位 净值 大涨 成为 收益冠军 上头 全球 天然资源 涨幅 黄金 类 油气 类 基金净值 涨幅 居前 港股 基金 总体 依然 表现 不佳 占据 跌幅 榜前列\n"
     ]
    }
   ],
   "source": [
    "texts = [] # 清洗后文本\n",
    "showi = 0\n",
    "showj = 1\n",
    "# print(comment[showi][showj])\n",
    "for i in range(len(comment)):\n",
    "    text = []\n",
    "    t1 = time.time()\n",
    "    for sentence in comment[i]:\n",
    "        chinese = pattern.findall(sentence) # 匹配中文：先分句\n",
    "        seg = [jieba.cut(c) for c in chinese] # 双重列表：句上分词\n",
    "        c = []\n",
    "        for ss in seg:\n",
    "            for s in ss:\n",
    "                if s not in stop: # 过滤停用词\n",
    "                    c.append(s)\n",
    "        text.append(\" \".join(c))\n",
    "    t2 = time.time()\n",
    "    texts.append(text)\n",
    "    print(\"comment_\" + str(i) + \" preprocessing time using %.5f s\" %(t2-t1))\n",
    "# 17:41-18:20 约 40 m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.csindex.com.cn/uploads/file/autofile/closeweight/000300closeweight.xls\n"
     ]
    }
   ],
   "source": [
    "# 计算个股主题因子得分 预备工作\n",
    "# 股票池：沪深300\n",
    "hs300 = ts.get_hs300s() \n",
    "hs300_code = hs300['code'].values.tolist()\n",
    "hs300_name = hs300['name'].values.tolist()\n",
    "concept_df = ts.get_concept_classified()\n",
    "industry_df = ts.get_industry_classified('sw')\n",
    "\n",
    "# 筛选出与股票池相关的概念\n",
    "concept = concept_df.loc[concept_df['code'].isin(hs300_code)]['c_name'].drop_duplicates().values.tolist() # 146\n",
    "# 筛选出与股票池相关的行业\n",
    "industry = industry_df.loc[industry_df['code'].isin(hs300_code)]['c_name'].drop_duplicates().values.tolist() # 104\n",
    "\n",
    "# 统计词频需要的模块\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# 1、全部文档前几个主题，假设1个文档可以属于多个主题，首先一定属于1个主题，后面几个主题只要满足在1.5倍的差距内，即 0.4*1.5 < 0.6 0.3*1.5 0.5\n",
    "def print_top_topics_number(model, count_matrix, k, topic_names, toptopicnames_list):\n",
    "    doctopic_matrix = model.fit_transform(count_matrix)\n",
    "    for doc_idx, doc in enumerate(doctopic_matrix):\n",
    "        for i in doc.argsort()[:-k - 1:-1]:\n",
    "            if i == doc.argsort()[:-k - 1:-1][0]:\n",
    "                toptopicnames_list.append(topic_names[i])\n",
    "                continue\n",
    "            elif round(doc[i], 2)*1.5 >= round(doc[doc.argsort()[:-k - 1:-1][0]], 2):\n",
    "                toptopicnames_list.append(topic_names[i])\n",
    "                \n",
    "# 3、热门主题关键词筛选，为每个主题选择前 N 个主题词\n",
    "def print_hottopic_keywords(model, topicnames, word_names, topickeywords_name, topickeywords_prob, n_top_words):\n",
    "    topicword_matrix = model.components_[topicnames]\n",
    "    for topic_idx,topic in enumerate(topicword_matrix):\n",
    "        topickeyword_name = [word_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]]\n",
    "        topickeywords_name.append(topickeyword_name)\n",
    "        topickeyword_prob = [round(topic[i], 2) for i in topic.argsort()[:-n_top_words - 1:-1]]\n",
    "        topickeywords_prob.append(topickeyword_prob)\n",
    "        \n",
    "# 4、计算每个主题：主题关键词概念/行业 归类信息\n",
    "def concept_industry_info(topickeywords_name, topickeywords_prob, concept_stay_list, concept_prob_list, industry_stay_list, industry_prob_list, topickeywords_weight_list):\n",
    "    for i in range(len(topickeywords_name)):\n",
    "        concept_num, industry_num = 0, 0\n",
    "        concept_stay, concept_prob = [], []\n",
    "        industry_stay, industry_prob = [], []\n",
    "        for j in range(topN):\n",
    "            name = topickeywords_name[i][j]\n",
    "            prob = topickeywords_prob[i][j]\n",
    "            for con in concept: # 与关键词相关概念 \n",
    "                if name in con:\n",
    "                    concept_stay.append(con)\n",
    "                    concept_prob.append(prob)\n",
    "                    concept_num = concept_num + 1\n",
    "            for ind in industry: # 与关键词相关行业 \n",
    "                if name in ind:\n",
    "                    industry_stay.append(ind)\n",
    "                    industry_prob.append(prob)\n",
    "                    industry_num = industry_num + 1\n",
    "        # 主题类别权重\n",
    "        if concept_num > 0 and industry_num > 0: # and place_num > 0:\n",
    "            topickeywords_weight = [0.5, 0.5]\n",
    "        elif concept_num == 0:\n",
    "            topickeywords_weight = [0, 1]\n",
    "        else:\n",
    "            topickeywords_weight = [1, 0]\n",
    "        \n",
    "        concept_stay_list.append(concept_stay)\n",
    "        concept_prob_list.append(concept_prob)\n",
    "        industry_stay_list.append(industry_stay)\n",
    "        industry_prob_list.append(industry_prob)\n",
    "        topickeywords_weight_list.append(topickeywords_weight)\n",
    "\n",
    "# 辅助函数：两列表对应元素相乘并求和\n",
    "def list_sum(a, b): \n",
    "    s = sum([a[i]*b[i] for i in range(len(a))])\n",
    "    return s\n",
    "\n",
    "# 5、匹配个股信息，计算因子得分，并标准化\n",
    "# # 获取单只股票的概念信息、行业信息 --> 从而得到股票主题得分\n",
    "def stock(stock_topicscore_list,concept_stay_list,concept_prob_list,industry_stay_list,industry_prob_list,topickeywords_weight_list):\n",
    "    for stock_code in hs300_code:\n",
    "        stock_concept = concept_df.loc[concept_df['code'] == stock_code]['c_name'].tolist()\n",
    "        stock_industry = industry_df.loc[industry_df['code'] == stock_code]['c_name'].tolist()\n",
    "        stock_topicscore = []\n",
    "        for i in range(topk): # 先计算每个主题得分，再加权得到总主题得分\n",
    "            concept_stay = concept_stay_list[i]\n",
    "            concept_prob = concept_prob_list[i]\n",
    "            industry_stay = industry_stay_list[i]\n",
    "            industry_prob = industry_prob_list[i]\n",
    "            topickeywords_weight = topickeywords_weight_list[i]\n",
    "            \n",
    "            concept_score = sum([concept_prob[i] for i in range(len(concept_stay)) if concept_stay[i] in stock_concept])\n",
    "            industry_score = sum([industry_prob[i] for i in range(len(industry_stay)) if industry_stay[i] in stock_industry])\n",
    "            ciscore_list = [concept_score,industry_score]\n",
    "            topicscore = list_sum(ciscore_list, topickeywords_weight)\n",
    "            stock_topicscore.append(topicscore)\n",
    "\n",
    "        stock_topicscore = list_sum(stock_topicscore, top_topicweight)\n",
    "        stock_topicscore_list.append(stock_topicscore)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 主函数\n",
    "def main(corpus,topic_factor):\n",
    "    # LDA主题建模\n",
    "    # 构建 Document-word matrix\n",
    "    count_vectorizer = CountVectorizer(stop_words=stop, min_df=0.005) # 特征选择：必须在文档总数的 0.5% 中出现过\n",
    "    count_matrix = count_vectorizer.fit_transform(corpus) # 词频矩阵\n",
    "    wordnames_list = count_vectorizer.get_feature_names() # 单词(特征)名称\n",
    "    print(count_matrix.shape) # ok\n",
    "    # 训练模型\n",
    "    k = 20 # 选择主题数\n",
    "    topicnames_list = [i for i in range(k)] # 主题名称\n",
    "    t1 = time.time()\n",
    "    lda = LatentDirichletAllocation(n_components=k, max_iter=50,learning_method='batch',random_state=1234)\n",
    "    lda.fit(count_matrix)\n",
    "    t2 = time.time()\n",
    "    print(\"lda modeling time using %.5f s\" %(t2-t1)) # ok 1 m\n",
    "    # 结果输出\n",
    "    t3 = time.time()\n",
    "    toptopicnames_list = [] # 主题名称，选择 topk = 5\n",
    "    print_top_topics_number(lda, count_matrix, k, topicnames_list, toptopicnames_list)\n",
    "    t4 = time.time()\n",
    "    print(\"calculate top topicname per doc using %.5f s\" %(t4-t3)) # ok 1 m\n",
    "    # 2.选择热门的前3-5个主题，要归一化\n",
    "    t5 = time.time()\n",
    "    topk = 5\n",
    "    top_topicnames = [Counter(toptopicnames_list).most_common(topk)[i][0] for i in range(topk)]\n",
    "    top_topicweight = [Counter(toptopicnames_list).most_common(topk)[i][1] for i in range(topk)]\n",
    "    top_topicweight = [i/sum(top_topicweight) for i in top_topicweight] # 归一化\n",
    "    t6 = time.time()\n",
    "    print(\"statistic top topicnames using %.5f s\" %(t6-t5)) # ok\n",
    "    # 3.热门主题关键词筛选，为每个主题选择前 topN 个主题词\n",
    "    t7 = time.time()\n",
    "    topN = 100\n",
    "    top_keywords_name, top_keywords_prob = [],[]\n",
    "    print_hottopic_keywords(lda, top_topicnames, wordnames_list, top_keywords_name, top_keywords_prob , topN)\n",
    "    t8 = time.time()\n",
    "    print(\"choose hottopic topkeywords using %.5f s\" %(t8-t7)) # ok\n",
    "    # 4.为主题关键词归类，正则匹配，找出与关键词相关的概念/行业等\n",
    "    t9 = time.time()\n",
    "    concept_stay_list, concept_prob_list, industry_stay_list, industry_prob_list, topickeywords_weight_list = [],[],[],[],[]\n",
    "    concept_industry_info(top_keywords_name, top_keywords_prob, concept_stay_list, concept_prob_list, industry_stay_list, industry_prob_list, topickeywords_weight_list)\n",
    "    t10 = time.time()\n",
    "    print(\"get concept industry info using %.5f s\" %(t10-t9)) # ok\n",
    "    # 5.计算个股主题因子值\n",
    "    t11 = time.time()\n",
    "    stock_topicscore_list = []\n",
    "    stock(stock_topicscore_list,concept_stay_list,concept_prob_list,industry_stay_list,industry_prob_list,topickeywords_weight_list)\n",
    "    # 因子值标准化\n",
    "    stock_topicscore_list = [(i-min(stock_topicscore_list))/(max(stock_topicscore_list)-min(stock_topicscore_list)) for i in stock_topicscore_list]\n",
    "    stock_topicfactor.append(stock_topicscore_list)\n",
    "    t12 = time.time()\n",
    "    print(\"calculate stock topicfactor using %.5f s\" %(t12-t11)) # ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2010, 6610)\n",
      "lda modeling time using 63.03303 s\n",
      "calculate top topicname per doc using 62.30640 s\n",
      "statistic top topicnames using 0.00096 s\n",
      "choose hottopic topkeywords using 0.00616 s\n",
      "[['资金', '反弹', '震荡', '大盘', '行情', '板块', '出现', '个股', '投资者', '指数', '短期', '上涨', '下跌', '走势', '股市', '持续', '调整', '主力', '机会', '两市', '股指', '涨幅', '预期', '风险', '关注', '跌幅', '表现', '创业板', '明显', '利好', '后市', '大幅', '业绩', '空间', '当前', '成交量', '热点', '有望', '因素', '连续', '杀跌', '突破', '支撑', '操作', '依然', '均线', '概率', '趋势', '估值', '向上', '策略', '回升', '压力', '盘面', '收盘', '形成', '券商', '上行', '行业', '尾盘', '技术', '较大', '维持', '处于', '盘中', '短线', '成交', '回落', '格局', '整体', '交易日', '附近', '再度', '影响', '仓位', '弱势', '前期', '建议', '方面', '小幅', '强势', '放量', '品种', '机构', '总体', '数据', '偏好', '情绪', '萎缩', '新高', '经济', '不断', '延续', '阶段', '缩量', '谨慎', '午后', '比较', '相对', '大跌'], ['中国', '股市', '经济', '全球', '美国', '这种', '需要', '投资者', '应该', '日本', '时间', '未来', '过去', '发生', '重要', '世界', '投资', '情况', '国家', '一次', '看到', '观点', '泡沫', '影响', '这是', '知道', '出现', '股票', '趋势', '机构', '最大', '机会', '长期', '希望', '新兴', '预测', '整个', '价值', '牛市', '波动', '以后', '最近', '能够', '觉得', '带来', '两个', '之前', '成为', '政府', '历史', '原因', '相信', '导致', '是否', '金融', '当时', '真正', '分析', '特别', '一种', '投机', '将会', '巨大', '过程', '这一', '事情', '国内', '尤其', '达到', '肯定', '判断', '一点', '经历', '价格', '越来越', '成功', '主权', '很大', '资本', '笔者', '正在', '至少', '简单', '看好', '环境', '完全', '利润', '之间', '面对', '标普', '股票市场', '不断', '选择', '似乎', '一下', '面临', '几个', '担心', '理解', '决定'], ['发展', '改革', '建设', '创新', '国家', '加强', '推动', '会议', '支持', '国务院', '完善', '重点', '开展', '促进', '我国', '重要', '习近平', '安全', '中国', '机制', '制度', '加快', '试点', '社会', '体系', '提高', '国际', '合作', '服务', '建立', '规划', '积极', '实现', '领域', '强调', '企业', '经济', '质量', '金融', '李克强', '意见', '十三', '提升', '召开', '指出', '保障', '提出', '要求', '方面', '标准', '农村', '基础', '组织', '坚持', '扩大', '深化', '地区', '就业', '总理', '落实', '研究', '进一步', '稳定', '绿色', '城市', '农业', '水平', '取得', '发挥', '流通', '政府', '任务', '疫苗', '教育', '做好', '能力', '结构性', '人民', '形成', '创业', '增强', '开放', '主席', '技术', '作用', '有效', '协调', '战略', '全国', '引导', '生产', '部门', '鼓励', '综合', '保护', '重大', '目标', '体制', '指导', '加大'], ['城市', '房价', '房地产', '深圳', '楼市', '住房', '上海', '北京', '上涨', '购房', '成交', '一线', '价格', '深港', '库存', '公积金', '调控', '二线', '记者', '贷款', '南京', '首付', '内地', '限购', '新政', '需求', '房子', '出台', '投资', '涨幅', '香港', '环比', '住宅', '出现', '显示', '增加', '苏州', '二手房', '供应', '土地', '面积', '平方米', '区域', '比例', '项目', '报道', '买房', '房产', '销售', '开发商', '缴存', '明显', '中心', '调整', '购买', '新房', '均价', '部分', '数据', '广州', '收入', '成交量', '购房者', '地震', '厦门', '情况', '研究院', '商品房', '地产', '人口', '三四', '资金', '两地', '减少', '下降', '万平方米', '户籍', '套房', '新建', '楼盘', '推出', '人士', '发布', '进入', '告诉', '达到', '居民', '影响', '最高', '成为', '研究', '同比', '全国', '下跌', '商品住宅', '指出', '收紧', '杭州', '连续', '游客'], ['指数', '美元', '美国', '美联储', '加息', '上涨', '预期', '油价', '全球', '下跌', '原油', '数据', '会议', '经济', '公布', '涨幅', '黄金', '日元', '大幅', '利率', '美股', '显示', '沙特', '股市', '协议', '冻产', '多哈', '收盘', '石油', '英国', '万桶', '增长', '大图', '产量', '影响', '反弹', '前值', '预计', '库存', '下滑', '收跌', '分析师', '产油国', '投资者', '达成', '跌幅', '维持', '收涨', '增加', '联储', '金价', '下降', '日本央行', '主要', '国际', '伊朗', '通胀', '主席', '表现', '能源', '小幅', '原油期货', '第一季度', '大涨', '新高', '欧洲', '期货', '俄罗斯', '首次', '最新', '风险', '德国', '综合', '最大', '就业', '货币政策', '耶伦', '标普', '水平', '财报', '日本', '报告', '收高', '关注', '减少', '价格', '平均', '当周', '强劲', '欧元', '行情', '连续', '鸽派', '新兴', '情绪', '进一步', '宣布', '震荡', '一度', '道琼斯']]\n",
      "get concept industry info using 0.00393 s\n",
      "calculate stock topicfactor using 0.61322 s\n"
     ]
    }
   ],
   "source": [
    "corpus = texts[0]\n",
    "stock_topicfactor = []\n",
    "main(corpus,stock_topicfactor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.csindex.com.cn/uploads/file/autofile/closeweight/000300closeweight.xls\n"
     ]
    }
   ],
   "source": [
    "topicfactor_df = pd.DataFrame(stock_topicfactor[0])\n",
    "topicfactor_df.columns = ['topicfactor']\n",
    "file_df = ts.get_hs300s()[['code','name']].join(topicfactor_df)\n",
    "file_df.to_csv(\"/Users/zhangjoy/Documents/vscode/py_project/lda/stock_topicfactor_0.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5910, 7035)\n",
      "lda modeling time using 191.75736 s\n",
      "calculate top topicname per doc using 197.56386 s\n",
      "statistic top topicnames using 0.00290 s\n",
      "choose hottopic topkeywords using 0.00658 s\n",
      "get concept industry info using 0.00406 s\n",
      "calculate stock topicfactor using 0.60861 s\n",
      "texts_3 all time using 392.48608 s\n",
      "(7428, 6594)\n",
      "lda modeling time using 215.91086 s\n",
      "calculate top topicname per doc using 221.84550 s\n",
      "statistic top topicnames using 0.00394 s\n",
      "choose hottopic topkeywords using 0.00610 s\n",
      "get concept industry info using 0.00404 s\n",
      "calculate stock topicfactor using 0.60445 s\n",
      "texts_4 all time using 441.19337 s\n",
      "(6840, 6429)\n",
      "lda modeling time using 199.36633 s\n",
      "calculate top topicname per doc using 198.64415 s\n",
      "statistic top topicnames using 0.00326 s\n",
      "choose hottopic topkeywords using 0.00605 s\n",
      "get concept industry info using 0.00406 s\n",
      "calculate stock topicfactor using 0.59733 s\n",
      "texts_5 all time using 401.12511 s\n",
      "(5567, 6765)\n",
      "lda modeling time using 164.76992 s\n",
      "calculate top topicname per doc using 168.43207 s\n",
      "statistic top topicnames using 0.00348 s\n",
      "choose hottopic topkeywords using 0.00633 s\n",
      "get concept industry info using 0.00465 s\n",
      "calculate stock topicfactor using 0.61249 s\n",
      "texts_6 all time using 335.97964 s\n",
      "(5426, 6619)\n",
      "lda modeling time using 157.96402 s\n",
      "calculate top topicname per doc using 163.48720 s\n",
      "statistic top topicnames using 0.00320 s\n",
      "choose hottopic topkeywords using 0.00643 s\n",
      "get concept industry info using 0.00432 s\n",
      "calculate stock topicfactor using 0.61377 s\n",
      "texts_7 all time using 324.13672 s\n",
      "(4705, 6758)\n",
      "lda modeling time using 136.66181 s\n",
      "calculate top topicname per doc using 130.44852 s\n",
      "statistic top topicnames using 0.00249 s\n",
      "choose hottopic topkeywords using 0.00636 s\n",
      "get concept industry info using 0.00393 s\n",
      "calculate stock topicfactor using 0.58140 s\n",
      "texts_8 all time using 269.51213 s\n",
      "(3670, 7196)\n",
      "lda modeling time using 99.89882 s\n",
      "calculate top topicname per doc using 104.69993 s\n",
      "statistic top topicnames using 0.00168 s\n",
      "choose hottopic topkeywords using 0.00642 s\n",
      "get concept industry info using 0.00392 s\n",
      "calculate stock topicfactor using 0.58076 s\n",
      "texts_9 all time using 206.59052 s\n"
     ]
    }
   ],
   "source": [
    "for i in range(3,10):\n",
    "    t1 = time.time()\n",
    "    corpus = texts[i]\n",
    "    stock_topicfactor = []\n",
    "    main(corpus,stock_topicfactor)\n",
    "    t2 = time.time()\n",
    "    print(\"texts_\" + str(i) + \" all time using %.5f s\" %(t2-t1))\n",
    "    print()\n",
    "    topicfactor_df = pd.DataFrame(stock_topicfactor[0])\n",
    "    factorname = 'topicfactor_' + str(i)\n",
    "    topicfactor_df.columns = [factorname]\n",
    "    file_df = file_df.join(topicfactor_df)\n",
    "\n",
    "file_df.to_csv(\"/Users/zhangjoy/Documents/vscode/py_project/lda/data/stock_topicfactor_9.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3843, 7171)\n",
      "lda modeling time using 101.77709 s\n",
      "calculate top topicname per doc using 103.42926 s\n",
      "statistic top topicnames using 0.00253 s\n",
      "choose hottopic topkeywords using 0.00852 s\n",
      "get concept industry info using 0.00450 s\n",
      "calculate stock topicfactor using 0.54466 s\n",
      "\n",
      "texts_10 all time using 207.21305 s\n",
      "(4664, 7198)\n",
      "lda modeling time using 129.01290 s\n",
      "calculate top topicname per doc using 132.29962 s\n",
      "statistic top topicnames using 0.00232 s\n",
      "choose hottopic topkeywords using 0.00652 s\n",
      "get concept industry info using 0.00391 s\n",
      "calculate stock topicfactor using 0.55418 s\n",
      "\n",
      "texts_11 all time using 263.64932 s\n",
      "(4741, 6810)\n",
      "lda modeling time using 126.77885 s\n",
      "calculate top topicname per doc using 139.02508 s\n",
      "statistic top topicnames using 0.00237 s\n",
      "choose hottopic topkeywords using 0.00639 s\n",
      "get concept industry info using 0.00393 s\n",
      "calculate stock topicfactor using 0.63553 s\n",
      "\n",
      "texts_12 all time using 268.09782 s\n",
      "(5181, 6757)\n",
      "lda modeling time using 153.35137 s\n",
      "calculate top topicname per doc using 156.13554 s\n",
      "statistic top topicnames using 0.00296 s\n",
      "choose hottopic topkeywords using 0.00699 s\n",
      "get concept industry info using 0.00551 s\n",
      "calculate stock topicfactor using 0.60849 s\n",
      "\n",
      "texts_13 all time using 312.11343 s\n",
      "(4732, 6879)\n",
      "lda modeling time using 143.78228 s\n",
      "calculate top topicname per doc using 148.00491 s\n",
      "statistic top topicnames using 0.00234 s\n",
      "choose hottopic topkeywords using 0.00657 s\n",
      "get concept industry info using 0.00420 s\n",
      "calculate stock topicfactor using 0.60827 s\n",
      "\n",
      "texts_14 all time using 294.27257 s\n",
      "(6799, 6366)\n",
      "lda modeling time using 195.43347 s\n",
      "calculate top topicname per doc using 200.25260 s\n",
      "statistic top topicnames using 0.00341 s\n",
      "choose hottopic topkeywords using 0.00590 s\n",
      "get concept industry info using 0.00397 s\n",
      "calculate stock topicfactor using 0.62479 s\n",
      "\n",
      "texts_15 all time using 398.82046 s\n",
      "(11211, 5523)\n",
      "lda modeling time using 288.54631 s\n",
      "calculate top topicname per doc using 296.53940 s\n",
      "statistic top topicnames using 0.00638 s\n",
      "choose hottopic topkeywords using 0.00523 s\n",
      "get concept industry info using 0.00420 s\n",
      "calculate stock topicfactor using 0.60770 s\n",
      "\n",
      "texts_16 all time using 589.09493 s\n",
      "(22565, 5222)\n",
      "lda modeling time using 581.85105 s\n",
      "calculate top topicname per doc using 573.95261 s\n",
      "statistic top topicnames using 0.01141 s\n",
      "choose hottopic topkeywords using 0.00561 s\n",
      "get concept industry info using 0.00422 s\n",
      "calculate stock topicfactor using 0.61823 s\n",
      "\n",
      "texts_17 all time using 1162.55583 s\n"
     ]
    }
   ],
   "source": [
    "for i in range(10,18):\n",
    "    t1 = time.time()\n",
    "    corpus = texts[i]\n",
    "    stock_topicfactor = []\n",
    "    main(corpus,stock_topicfactor)\n",
    "    t2 = time.time()\n",
    "    print(\"texts_\" + str(i) + \" all time using %.5f s\" %(t2-t1))\n",
    "    print()\n",
    "    topicfactor_df = pd.DataFrame(stock_topicfactor[0])\n",
    "    factorname = 'topicfactor_' + str(i)\n",
    "    topicfactor_df.columns = [factorname]\n",
    "    file_df = file_df.join(topicfactor_df)\n",
    "\n",
    "file_df.to_csv(\"/Users/zhangjoy/Documents/vscode/py_project/lda/data/stock_topicfactor_17.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
